#1 - Think of removing outliers from the sample before creating the model

#Pearson Correlation Coefficient and p-value
#input x and y as array
#output (Pearson coefficient, p-value) tuple
 
 import scipy as sp
 result = sp.stats.pearsonr( dataset['x'] , dataset['y'] )

#Correlation matrix of all variables

 result = dataset.corr()

#Linear Regression, x input may have the indexes being a 2D dataframe
 
 x = dataset[['x']]
 y = dataset['y']
 from sklearn.linear_model import LinearRegression
 lm = LinearRegression()
 lm.fit( x,y )
 result = pandas.DataFrame( {'Coefficient': lm_coef_ , 'Intercept': lm_intercept_ , 'R2': lm_score(x,y) } )

#Multiple Linear regression, x's inputs may have the indexes being a 2D dataframe

 xs = dataset[['x1','x2','x3','x4','x5']]
 y = dataset['y']
 lm.fit( xs,y )
 result = pandas.DataFrame( {'Coefficients': lm_coef_, 'Intercept': lm_intercept_ , 'R2': lm_score(xs,y) } )

#Polynomial Regression of 3rd order

 import numpy as np
 f = np.polyfit( dataset['x'] , dataset['y'] , 3 ) #return an array with the 3 coefficients and the intercept
 p = np.poly1d( f ) #return a numpy.poly1d object
 result = pandas.DataFrame( {'Coefficients': p } )
  
#Multiple Polynomial Regression of 2nd order 
#Y = a + b1x1 + b2x2 + b3x1x2 + b4x1² + b5x2²
#First, we need to transform the features in a polynomial equations before deploying the model

 from sklearn.preprocessing import PolynomialFeatures
 pr = PolynomialFeatures(degree=2)
 dataset_pr = pr.fit_transform( dataset )
 result = pandas.DataFrame( {'Equations': dataset_pr } )
 
#Pipeline to do a Polynomial Regression within one line

 from sklearn.pipeline import Pipeline
 from sklearn.preprocessing import StandardScaler
 
 #We create the pipeline, by creating a list of tuples including the name of the model or estimator and its corresponding constructor.
 Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]
 pipe=Pipeline(Input)
 
 xs = dataset[['x1','x2','x3','x4','x5']]
 y = dataset['y']
 pipe.fit( xs , y )

 ypipe=pipe.predict( xs )
 

#Mean Squared Error (MSE)

 from sklearn.metrics import mean_squared_error
 MSE = mean_squared_error(dataset['y'], y_predict)

#R-squared (R²)

 from sklearn.linear_model import LinearRegression
 LinearRegression.score(X,y)
